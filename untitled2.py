# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1p0SqARDXvn2qI2M3lB0_cs4FcuiMOD-p
"""

import numpy as np

# supose we have rating matrix of 5 users and 5 items, 0 value means that an user 'i' didn't  rate  an item 'j'
data = np.array([
    [3, 5, 2, 0],
    [2, 1, 0, 4],
    [1, 0, 0, 3],
    [0, 5, 0, 4],
    [0, 3, 2, 5],
])

num_users= data.shape[0]
num_movie=data.shape[1]
K=2       # number of factors
alpha=0.1 # learning rate parameter
beta=0.01 # regularization parameter 
iterations=20 # number of epochs

#  Initialize user  feature vector
Pu = np.random.normal(scale=1./K, size=(num_users,K))
#  Initialize movie  feature vector
Qi = np.random.normal(scale=1./K, size=(num_movie,K))

# Initialize the biases
bu = np.zeros(num_users)
bi = np.zeros(num_movie)
b = np.mean(data[np.where(data != 0)])

# Create a list of training samples
samples = [(i, j, data[i, j])
  for i in range(num_users)
  for j in range(num_movie)
  if data[i, j] > 0
]

# training 
training = []
for i in range(iterations):
  np.random.shuffle(samples)

  # stocastic gradient decent
  for i, j, r in samples:    
    prediction = b + bu[i] + bi[j] + Pu[i, :].dot(Qi[j, :].T)
    e = (r - prediction)
    # Update biases
    bu[i] += alpha * (e - beta * bu[i])
    bi[j] += alpha * (e - beta * bi[j])

    # Update user and item latent feature matrices
    Pu[i, :] += alpha * (e * Qi[j, :] - beta * Pu[i,:])
    Qi[j, :] += alpha * (e * Pu[i, :] -beta * Qi[j,:])

  xs, ys = data.nonzero()
  predicted = b + bu[:,np.newaxis] + bi[np.newaxis:,] + Pu.dot(Qi.T)
  error = 0
  for x, y in zip(xs, ys):
    error += pow(data[x, y] - predicted[x, y], 2)
  mse=np.sqrt(error)
  training.append((i, mse))

# predict the missing rate 
print(predicted)

#mean square error
print(mse)

#user vector
print(Pu)

#feature vector of the first user 
print(Pu[0])

#Item vector
print(Qi)

# user bais  
print(bu)

#user items 
print(bi)